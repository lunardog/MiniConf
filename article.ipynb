{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ディープラーニングのホットドッグ検出器のレシピ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "研究開発部の画像解析の担当のレシェックです。techlife を書くのは初めてです。よろしくお願いいたします。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最先端の機械学習を使うためには、いつも自分のスキルアップが必要です。そのために、毎日論文を読んだり、新しいオープンソースのコードを試してみたり、クックパッドのデータで実験しています。これはちょっと料理の練習と似ています。時々新しいモデルを学習させるのは料理をオーブンに入れるのと同じ気持ちです。オーブンの温度とか、学習率と同じで、低すぎだとよく焼けず、高すぎだと焦げてしまいます。しかし、ちゃんと他のリサーチャーの論文やブログの中のレシピを見ながら、自分のデータでモデルを学習させると失敗せずに済むかもしれません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この開発者ブログでは、クックパッドの機械学習のレシピを紹介したいと思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hot dog highlight](images/picnic-993906_640-processed.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このブログで使っているテスト画像は[Pixabay](http://pixabay.com)から取得した、Creative Commonsのライセンスの写真です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 説明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "クックパッドは[料理/非料理のモデル](http://techlife.cookpad.com/entry/2017/09/14/161756)を開発しています。ここでは、このモデルのミニチュア版のレシピを紹介します。カテゴリは「料理」と「非料理」の代わりに、「ホットドッグ」と「非ホットドッグ」にします。そして、パッチ化した画像に対する認識モデルを使って、画像の中でホットドッグがどこにあるかを検出します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 調理器具"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - python\n",
    " - Keras\n",
    " - numpy\n",
    " - pillow (PIL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Keras](https://keras.io/ja/)はTensorflow、CNTKやTheano上で動く高水準のライブラリーです。Keras は特に画像データに対して、単なる学習以外にも前処理などでも様々な機能があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 材料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggleから、[Hot Dog - Not Hot Dog](https://www.kaggle.com/dansbecker/hot-dog-not-hot-dog/data)のデーターセットをダウンロードしてください。Kaggleに登録が必要です。\n",
    "\n",
    "ダウンロードした後、`seefood.zip`を`unzip`してください。\n",
    "\n",
    "アーカイブの中に、2つのディレクトリ：`train`と`test`があります：\n",
    "```\n",
    "seefood/train/not_hot_dog\n",
    "seefood/train/hot_dog\n",
    "seefood/test/not_hot_dog\n",
    "seefood/test/hot_dog\n",
    "```\n",
    "`hot_dog`ディレクトリの中にホットドッグの画像が入っており、`not_hot_dog`の中にそれ以外の画像が入っています。新しい機械学習のレシピを開発する時は、テストデータを分けた方がいいですが、今回の場合は画像が少ないので、テストデータも学習に使いましょう。\n",
    "```\n",
    "mkdir seefood/all\n",
    "cp -r seefood/test/* seefood/train/* seefood/all\n",
    "```\n",
    "以降では、`seefood/all`のディレクトリを使います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ拡張"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras のモバイルネットは（224px・224px）のフィックスサイズの画像しか認識できないので、これから学習や認識用にサイズを変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leszek-rybicki/.pyenv/versions/3.6.0/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/leszek-rybicki/.pyenv/versions/3.6.0/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import tensorflowjs as tfjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_SIZE=[224, 224]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "テストデータを学習に使っても、このデータセットはまだ小さいので、データ拡張を使いましょう。\n",
    "\n",
    "Kerasの`ImageDataGenerator`は学習時に、画像を一つずつ変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.preprocessing.image\n",
    "\n",
    "image_generator = keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.0,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        rotation_range=10,\n",
    "        fill_mode=\"wrap\",\n",
    "        vertical_flip=True,\n",
    "        horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上の`image_generator`を`\"seefood/all\"`のディレクトリで動かします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 998 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = image_generator.flow_from_directory(\n",
    "    \"seefood/all\",\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    classes=[\"not_hot_dog\", \"hot_dog\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの作り方\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のレシピでは、3 個のモデルを 3 層のスポンジケーキのように積み重ねています。\n",
    "\n",
    "1. `base_model`はMobileNetです。転移学習のために使います。\n",
    "2. その上の、`patch_model`は画像のパッチごとに分類できます。\n",
    "3. さらにその上の`classifier`は「ホットドッグ」や「非ホットドッグ」の二値分類器です。\n",
    "\n",
    "まず`keras`を`import`します："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ベースとして、Googleで開発されたMobileNetというモデルを使います。\n",
    "\n",
    "`weights=\"imagenet\"`は、ILSVRCのコンペティションのデータセットで学習されたパラメタを使って、転移学習することを意味しています"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model = keras.applications.mobilenet.MobileNet(\n",
    "    input_shape=IMG_SIZE + [3], \n",
    "    weights=\"imagenet\",\n",
    "    include_top=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ベースモデルの一番上のフィーチャサイズは1024です。パッチレイヤが学習できるようにちょっと下げましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop1 =base_model.output\n",
    "conv_filter = keras.layers.convolutional.Conv2D(\n",
    "    4, (1,1),\n",
    "    activation=\"relu\",\n",
    "    use_bias=True,\n",
    "    kernel_regularizer=keras.regularizers.l2(0.001)\n",
    ")(drop1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "パッチレイヤもConv2Dのタイプのレイヤです。この場合、`softmax`を使えば、パッチごとに分類できるようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop2 = conv_filter\n",
    "patch = keras.layers.convolutional.Conv2D(\n",
    "    2, (3, 3),\n",
    "    name=\"patch\",\n",
    "    activation=\"softmax\",\n",
    "    use_bias=True,\n",
    "    padding=\"same\",\n",
    "    kernel_regularizer=keras.regularizers.l2(0.001)\n",
    ")(drop2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これでパッチモデルができました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patch_model = keras.models.Model(\n",
    "    inputs=base_model.input, \n",
    "    outputs=patch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "パッチモデルをベースにして、最後の出力レイヤを追加して分類モデルを作ります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pool = keras.layers.GlobalAveragePooling2D()(patch)\n",
    "logits = keras.layers.Activation(\"softmax\")(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = keras.models.Model(\n",
    "    inputs=base_model.input, \n",
    "    outputs=logits\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ベースモデルは学習させません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そしで、全体のモデルを`compile`します："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では、学習を始めましょう！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "いくつか実験をした結果、以下のようにnot_hot_dogのクラスのclass_weightを高くするほうが良いことが分かりました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 136s 4s/step - loss: 0.2953 - acc: 0.4949\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 258s 8s/step - loss: 0.2671 - acc: 0.5977\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 139s 4s/step - loss: 0.2490 - acc: 0.6996\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 121s 4s/step - loss: 0.2351 - acc: 0.7668\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 114s 4s/step - loss: 0.2393 - acc: 0.7498\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 139s 4s/step - loss: 0.2370 - acc: 0.7467\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 153s 5s/step - loss: 0.2314 - acc: 0.7801\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 148s 5s/step - loss: 0.2371 - acc: 0.7553\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 146s 5s/step - loss: 0.2274 - acc: 0.8024\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 136s 4s/step - loss: 0.2277 - acc: 0.8014\n",
      "CPU times: user 1h 6min 57s, sys: 2min 10s, total: 1h 9min 8s\n",
      "Wall time: 24min 50s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11b0070f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "classifier.fit_generator(\n",
    "    train_generator, \n",
    "    class_weight={0: .75, 1: .25}, \n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfjs.converters.save_keras_model(patch_model, './model/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このデータセットの場合、１０エポックぐらいが良さそうです。パッチベースを使っているので、精度は１００％にならないほうがいいです。７０％ぐらいがちょうどいいです。\n",
    "\n",
    "私の MacBook Pro では１０エポックで２０分ぐらいかかりました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## チェック"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像とデータの変換のために、PILとnumpyを使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像をインファレンスする前に、`numpy`のデータに変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def patch_infer(img):\n",
    "    data = np.array(img.resize(IMG_SIZE))/255.0\n",
    "    patches = patch_model.predict(data[np.newaxis])\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そして、元の画像とインファレンス結果をビジュアライズします："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def overlay(img, patches, threshold=0.99):\n",
    "    # transposeはパッチをクラスごとに分けます。\n",
    "    patches = patches[0].transpose(2, 0, 1)\n",
    "    # hot_dogパッチ - not_hot_dogパッチ\n",
    "    patches = patches[1] - patches[0]\n",
    "    # 微妙なパッチをなくして\n",
    "    patches = np.clip(patches, threshold, 1.0)\n",
    "    patches = 255.0 * (patches - threshold) / (1.0 - threshold)\n",
    "    # 数字を画像にして\n",
    "    patches = Image.fromarray(patches.astype(np.uint8)).resize(img.size, Image.BICUBIC)\n",
    "    # もとの画像を白黒に\n",
    "    grayscale = img.convert(\"L\").convert(\"RGB\").point(lambda p: p * 0.5)\n",
    "    # パッチをマスクに使って、元の画像と白黒の画像をあわせて\n",
    "    composite = Image.composite(img, grayscale, patches)\n",
    "    return composite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まとめて、インファレンスとビジュアライズを一つのファンクションにすると："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(path, border=8):\n",
    "    img = Image.open(path)\n",
    "    patches = patch_infer(img)\n",
    "    result = overlay(img, patches)\n",
    "    # 元の画像と変換された画像をカンバスに並べます\n",
    "    canvas = Image.new(\n",
    "        mode=\"RGB\", \n",
    "        size=(img.width * 2 + border, img.height), \n",
    "        color=\"white\")\n",
    "    canvas.paste(img, (0,0))\n",
    "    canvas.paste(result, (img.width + border, 0))\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for filename in os.listdir(\"images\"):\n",
    "    path = os.path.join(\"images\", filename)\n",
    "    if not path.endswith(\"640.jpg\"):\n",
    "        continue\n",
    "    canvas = process_image(path)\n",
    "    canvas.save(path.replace('.jpg', '-processed.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "では、結果を見てみましょう！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CC0 by NadinLisa](images/barbecue-283889_640-processed.jpg)\n",
    "きれいですね！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CC0 by pairswing](images/coffee-2429489_640-processed.jpg)\n",
    "ホットドッグの色はちょっととなりのコーヒーに移りましたが、ほとんど大丈夫です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CC0 by HannahChen](images/hot-dog-657039_640-processed.jpg)\n",
    "フォーカスが足りないところは認識にならなかったみたいです。なぜでしょう？学習データにフォーカスが当たらないホットドッグがなかったからです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CC0 by skeeze](images/picnic-993906_640-processed.jpg)\n",
    "こちらも、左側のホットドッグはフォーカスが当たっておらず、モデルはホットドッグを認識できませんでした。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "ホットドッグではない画像は？\n",
    "![CC0 by sharonang](images/fish-and-chip-3039746_640-processed.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CC0 by dimitrisvetsikas1969](images/cat-3276083_640-processed.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CC0 by wildfaces](images/dog-3289600_640-processed.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CC0 by Free Photos](images/vw-camper-336606_640-processed.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "ホットドッグではない画像には、パッチはゼロやゼロに近い値になります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "転移学習を使えば、データが少なくても、それなりの識別器が作れますね！\n",
    "\n",
    "パッチごとの分類を使えば、画像の中の認識したいフィーチャーを可視化できます。\n",
    "\n",
    "モバイルネット(MobileNet)のおかげで、CPU でもモデルを学習できます。\n",
    "\n",
    "いかがでしたでしょうか。 クックパッドでは、機械学習を用いて新たなサービスを創り出していける方を募集しています。 興味のある方はぜひ話を聞きに遊びに来て下さい。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
